[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "Data",
        "importPath": "torch_geometric.data",
        "description": "torch_geometric.data",
        "isExtraImport": true,
        "detail": "torch_geometric.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch_geometric.loader",
        "description": "torch_geometric.loader",
        "isExtraImport": true,
        "detail": "torch_geometric.loader",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "GCNConv",
        "importPath": "torch_geometric.nn",
        "description": "torch_geometric.nn",
        "isExtraImport": true,
        "detail": "torch_geometric.nn",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "Series",
        "importPath": "pandas",
        "description": "pandas",
        "isExtraImport": true,
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "importPath": "sklearn",
        "description": "sklearn",
        "isExtraImport": true,
        "detail": "sklearn",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "Marconi100Room",
        "importPath": "room",
        "description": "room",
        "isExtraImport": true,
        "detail": "room",
        "documentation": {}
    },
    {
        "label": "Marconi100Room",
        "importPath": "room",
        "description": "room",
        "isExtraImport": true,
        "detail": "room",
        "documentation": {}
    },
    {
        "label": "ast",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ast",
        "description": "ast",
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "Figure",
        "importPath": "matplotlib.figure",
        "description": "matplotlib.figure",
        "isExtraImport": true,
        "detail": "matplotlib.figure",
        "documentation": {}
    },
    {
        "label": "Axes",
        "importPath": "matplotlib.axes",
        "description": "matplotlib.axes",
        "isExtraImport": true,
        "detail": "matplotlib.axes",
        "documentation": {}
    },
    {
        "label": "GCNDataManager",
        "importPath": "gcn_manager",
        "description": "gcn_manager",
        "isExtraImport": true,
        "detail": "gcn_manager",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "DecisionTreeClassifier",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "shuffle",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "shuffle",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "pytz",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytz",
        "description": "pytz",
        "detail": "pytz",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "ThreadPoolExecutor",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "as_completed",
        "importPath": "concurrent.futures",
        "description": "concurrent.futures",
        "isExtraImport": true,
        "detail": "concurrent.futures",
        "documentation": {}
    },
    {
        "label": "reduce",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "lru_cache",
        "importPath": "functools",
        "description": "functools",
        "isExtraImport": true,
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "gzip",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "gzip",
        "description": "gzip",
        "detail": "gzip",
        "documentation": {}
    },
    {
        "label": "urllib.request,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request.",
        "description": "urllib.request.",
        "detail": "urllib.request.",
        "documentation": {}
    },
    {
        "label": "http.client",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "http.client",
        "description": "http.client",
        "detail": "http.client",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "StringIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "cached",
        "importPath": "cachetools",
        "description": "cachetools",
        "isExtraImport": true,
        "detail": "cachetools",
        "documentation": {}
    },
    {
        "label": "FanoutCache",
        "importPath": "diskcache",
        "description": "diskcache",
        "isExtraImport": true,
        "detail": "diskcache",
        "documentation": {}
    },
    {
        "label": "zlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zlib",
        "description": "zlib",
        "detail": "zlib",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Examon",
        "importPath": "examon.examon",
        "description": "examon.examon",
        "isExtraImport": true,
        "detail": "examon.examon",
        "documentation": {}
    },
    {
        "label": "ExamonQL",
        "importPath": "examon.examon",
        "description": "examon.examon",
        "isExtraImport": true,
        "detail": "examon.examon",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "time,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time.",
        "description": "time.",
        "detail": "time.",
        "documentation": {}
    },
    {
        "label": "data_extraction",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "data_extraction",
        "description": "data_extraction",
        "detail": "data_extraction",
        "documentation": {}
    },
    {
        "label": "preprocessing",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "preprocessing",
        "description": "preprocessing",
        "detail": "preprocessing",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inference",
        "description": "inference",
        "detail": "inference",
        "documentation": {}
    },
    {
        "label": "publishing_results",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "publishing_results",
        "description": "publishing_results",
        "detail": "publishing_results",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "logging_module",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging_module",
        "description": "logging_module",
        "detail": "logging_module",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "logging_module",
        "description": "logging_module",
        "isExtraImport": true,
        "detail": "logging_module",
        "documentation": {}
    },
    {
        "label": "logging",
        "importPath": "logging_module",
        "description": "logging_module",
        "isExtraImport": true,
        "detail": "logging_module",
        "documentation": {}
    },
    {
        "label": "datetime,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime.",
        "description": "datetime.",
        "detail": "datetime.",
        "documentation": {}
    },
    {
        "label": "paho.mqtt.client",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "paho.mqtt.client",
        "description": "paho.mqtt.client",
        "detail": "paho.mqtt.client",
        "documentation": {}
    },
    {
        "label": "AP_SequenceDataset",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "description": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "peekOfCode": "class AP_SequenceDataset(Dataset):\n  def __init__(self, seq_length:int ,task:str):\n    self.task = task\n    if(self.task == 'train'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/train\".format(fw))\n    elif(self.task == 'test'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/test\".format(fw))\n    elif(self.task == 'val'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/val\".format(fw))\n    else:",
        "detail": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "documentation": {}
    },
    {
        "label": "GNN",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "description": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "peekOfCode": "class GNN(torch.nn.Module):\n  def __init__(self, in_dim, hidden_dim,dropout_prob):\n      super().__init__()\n      self.conv1 = GCNConv(in_dim, hidden_dim)\n      self.conv2 = GCNConv(hidden_dim,in_dim)\n      # Batch Normalization layers\n      self.bn1 = torch.nn.BatchNorm1d(hidden_dim)\n      self.bn2 = torch.nn.BatchNorm1d(in_dim)\n      # Dropout layers\n      self.dropout = torch.nn.Dropout(dropout_prob)",
        "detail": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "description": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "peekOfCode": "class LSTM(torch.nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n        super(LSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        # LSTM layer\n        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        # Output layer\n        self.fc = torch.nn.Linear(hidden_size, output_size)\n    def forward(self, x):",
        "detail": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "description": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "peekOfCode": "inpts = sys.argv\nfw = int(inpts[1])\nexperiment = str(inpts[2])\nclass AP_SequenceDataset(Dataset):\n  def __init__(self, seq_length:int ,task:str):\n    self.task = task\n    if(self.task == 'train'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/train\".format(fw))\n    elif(self.task == 'test'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/test\".format(fw))",
        "detail": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "documentation": {}
    },
    {
        "label": "fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "description": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "peekOfCode": "fw = int(inpts[1])\nexperiment = str(inpts[2])\nclass AP_SequenceDataset(Dataset):\n  def __init__(self, seq_length:int ,task:str):\n    self.task = task\n    if(self.task == 'train'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/train\".format(fw))\n    elif(self.task == 'test'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/test\".format(fw))\n    elif(self.task == 'val'):",
        "detail": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "documentation": {}
    },
    {
        "label": "experiment",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "description": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "peekOfCode": "experiment = str(inpts[2])\nclass AP_SequenceDataset(Dataset):\n  def __init__(self, seq_length:int ,task:str):\n    self.task = task\n    if(self.task == 'train'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/train\".format(fw))\n    elif(self.task == 'test'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/test\".format(fw))\n    elif(self.task == 'val'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/val\".format(fw))",
        "detail": "examples.GRAAFE.Offline.Additional Experiments.gcn_lstm",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.results_setup",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.results_setup",
        "peekOfCode": "model = '../Training_and_validation_of_ML_models/results'\nos.mkdir(model)\nfor fw in [4,6,12,24,32,64,96,192,288]:\n    os.mkdir(\"../Training_and_validation_of_ML_models/{}/{}\".format(model,fw))\nshutil.copy(\"roc_avg.py\", \"../Training_and_validation_of_ML_models/{}/roc_avg.py\".format(model))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.results_setup",
        "documentation": {}
    },
    {
        "label": "remove_rows_with_preceding_one",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "peekOfCode": "def remove_rows_with_preceding_one(df):\n    #Shift the true_class column by one row\n    shifted = df['true_class'].shift()\n    #Select the rows where the shifted column does not have a value of 1\n    filtered = df[shifted != 1]\n    return filtered\nfor fw in FW:\n    dir_path = '{}/'.format(fw)\n    files = []\n    # loop over the contents of the directory",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "documentation": {}
    },
    {
        "label": "roc_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "peekOfCode": "roc_list = []\nFW = [4,6,12,24,32,64,96,192,288]\ndef remove_rows_with_preceding_one(df):\n    #Shift the true_class column by one row\n    shifted = df['true_class'].shift()\n    #Select the rows where the shifted column does not have a value of 1\n    filtered = df[shifted != 1]\n    return filtered\nfor fw in FW:\n    dir_path = '{}/'.format(fw)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "documentation": {}
    },
    {
        "label": "FW",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "peekOfCode": "FW = [4,6,12,24,32,64,96,192,288]\ndef remove_rows_with_preceding_one(df):\n    #Shift the true_class column by one row\n    shifted = df['true_class'].shift()\n    #Select the rows where the shifted column does not have a value of 1\n    filtered = df[shifted != 1]\n    return filtered\nfor fw in FW:\n    dir_path = '{}/'.format(fw)\n    files = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.roc_avg",
        "documentation": {}
    },
    {
        "label": "fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "fw = [4,6,12,24,32,64,96,192,288]\nprob_fw = []\nl_fw = []\nfiles = ['data/12_4.pickle',\n         'data/12_6.pickle',\n         'data/12_12.pickle',\n         'data/12_24.pickle',\n         'data/12_32.pickle',\n         'data/12_64.pickle',\n         'data/12_96.pickle',",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_fw = []\nl_fw = []\nfiles = ['data/12_4.pickle',\n         'data/12_6.pickle',\n         'data/12_12.pickle',\n         'data/12_24.pickle',\n         'data/12_32.pickle',\n         'data/12_64.pickle',\n         'data/12_96.pickle',\n         'data/12_192.pickle',",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "l_fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "l_fw = []\nfiles = ['data/12_4.pickle',\n         'data/12_6.pickle',\n         'data/12_12.pickle',\n         'data/12_24.pickle',\n         'data/12_32.pickle',\n         'data/12_64.pickle',\n         'data/12_96.pickle',\n         'data/12_192.pickle',\n         'data/12_288.pickle']",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "files = ['data/12_4.pickle',\n         'data/12_6.pickle',\n         'data/12_12.pickle',\n         'data/12_24.pickle',\n         'data/12_32.pickle',\n         'data/12_64.pickle',\n         'data/12_96.pickle',\n         'data/12_192.pickle',\n         'data/12_288.pickle']\nprint(files)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "data = pd.read_parquet(\"240.parquet\")\ndata = data.dropna()\ndata.reset_index(drop=True, inplace = True)\ndata['value'] = data['value'].replace(2,1)\ndata['value'] = data['value'].replace(3,1)\nprint(data.shape)\nvalue = data['value'].to_numpy()\nvalue = value[int(data.shape[0]*0.8):]\ntrue = value[:13507]\nprint(true)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "data = data.dropna()\ndata.reset_index(drop=True, inplace = True)\ndata['value'] = data['value'].replace(2,1)\ndata['value'] = data['value'].replace(3,1)\nprint(data.shape)\nvalue = data['value'].to_numpy()\nvalue = value[int(data.shape[0]*0.8):]\ntrue = value[:13507]\nprint(true)\nts = data['timestamp'].to_numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "data['value']",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "data['value'] = data['value'].replace(2,1)\ndata['value'] = data['value'].replace(3,1)\nprint(data.shape)\nvalue = data['value'].to_numpy()\nvalue = value[int(data.shape[0]*0.8):]\ntrue = value[:13507]\nprint(true)\nts = data['timestamp'].to_numpy()\nts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "data['value']",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "data['value'] = data['value'].replace(3,1)\nprint(data.shape)\nvalue = data['value'].to_numpy()\nvalue = value[int(data.shape[0]*0.8):]\ntrue = value[:13507]\nprint(true)\nts = data['timestamp'].to_numpy()\nts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]\nprint(len(true),len(ts))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "value",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "value = data['value'].to_numpy()\nvalue = value[int(data.shape[0]*0.8):]\ntrue = value[:13507]\nprint(true)\nts = data['timestamp'].to_numpy()\nts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]\nprint(len(true),len(ts))\nprob_4 = prob_fw[0]\nprob_6 = prob_fw[1]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "value",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "value = value[int(data.shape[0]*0.8):]\ntrue = value[:13507]\nprint(true)\nts = data['timestamp'].to_numpy()\nts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]\nprint(len(true),len(ts))\nprob_4 = prob_fw[0]\nprob_6 = prob_fw[1]\nprob_12 = prob_fw[2]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "true",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "true = value[:13507]\nprint(true)\nts = data['timestamp'].to_numpy()\nts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]\nprint(len(true),len(ts))\nprob_4 = prob_fw[0]\nprob_6 = prob_fw[1]\nprob_12 = prob_fw[2]\nprob_24 = prob_fw[3]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "ts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "ts = data['timestamp'].to_numpy()\nts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]\nprint(len(true),len(ts))\nprob_4 = prob_fw[0]\nprob_6 = prob_fw[1]\nprob_12 = prob_fw[2]\nprob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "ts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "ts = ts[int(data.shape[0]*0.8):]\nts = ts[:13507]\nprint(len(true),len(ts))\nprob_4 = prob_fw[0]\nprob_6 = prob_fw[1]\nprob_12 = prob_fw[2]\nprob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "ts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "ts = ts[:13507]\nprint(len(true),len(ts))\nprob_4 = prob_fw[0]\nprob_6 = prob_fw[1]\nprob_12 = prob_fw[2]\nprob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_4",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_4 = prob_fw[0]\nprob_6 = prob_fw[1]\nprob_12 = prob_fw[2]\nprob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_6",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_6 = prob_fw[1]\nprob_12 = prob_fw[2]\nprob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_12",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_12 = prob_fw[2]\nprob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_24",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_24 = prob_fw[3]\nprob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_32",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_32 = prob_fw[4]\nprob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,\n'TW 24': prob_24,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_64",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_64 = prob_fw[5]\nprob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,\n'TW 24': prob_24,\n'TW 32': prob_32,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_96",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_96 = prob_fw[6]\nprob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,\n'TW 24': prob_24,\n'TW 32': prob_32,\n'TW 64': prob_64,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_192",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_192 = prob_fw[7]\nprob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,\n'TW 24': prob_24,\n'TW 32': prob_32,\n'TW 64': prob_64,\n'TW 96': prob_96,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "prob_288",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "prob_288 = prob_fw[8]\ndf_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,\n'TW 24': prob_24,\n'TW 32': prob_32,\n'TW 64': prob_64,\n'TW 96': prob_96,\n'TW 192': prob_192,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df_heat",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df_heat = pd.DataFrame({'raw a.label': true,\n'TW 4': prob_4,\n'TW 6': prob_6,\n'TW 12': prob_12,\n'TW 24': prob_24,\n'TW 32': prob_32,\n'TW 64': prob_64,\n'TW 96': prob_96,\n'TW 192': prob_192,\n'TW 288': prob_288,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "scaler = preprocessing.MinMaxScaler()\nnames = df_heat.columns\nd = scaler.fit_transform(df_heat)\ndf_heat = pd.DataFrame(d, columns=names)\ndf_heat['Timestamp'] = ts\na = df_heat['Timestamp'].dt.date\na = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "names",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "names = df_heat.columns\nd = scaler.fit_transform(df_heat)\ndf_heat = pd.DataFrame(d, columns=names)\ndf_heat['Timestamp'] = ts\na = df_heat['Timestamp'].dt.date\na = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])\n        a.append(t)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "d = scaler.fit_transform(df_heat)\ndf_heat = pd.DataFrame(d, columns=names)\ndf_heat['Timestamp'] = ts\na = df_heat['Timestamp'].dt.date\na = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])\n        a.append(t)\n    else:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df_heat",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df_heat = pd.DataFrame(d, columns=names)\ndf_heat['Timestamp'] = ts\na = df_heat['Timestamp'].dt.date\na = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])\n        a.append(t)\n    else:\n        a.append(\"0\")",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df_heat['Timestamp']",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df_heat['Timestamp'] = ts\na = df_heat['Timestamp'].dt.date\na = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])\n        a.append(t)\n    else:\n        a.append(\"0\")\na[6738] = '18:00'",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "a = df_heat['Timestamp'].dt.date\na = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])\n        a.append(t)\n    else:\n        a.append(\"0\")\na[6738] = '18:00'\ndf_heat['Time (HH:MM)'] = a ",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "a = []\nfor i in tqdm(range(df_heat.shape[0])):\n    if((i>=6630) & (i<=6740)):\n        t = str(df_heat['Timestamp'].dt.strftime('%H:%M')[i])\n        a.append(t)\n    else:\n        a.append(\"0\")\na[6738] = '18:00'\ndf_heat['Time (HH:MM)'] = a \ndf_heat = df_heat.drop(['Timestamp'],axis = 1)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "a[6738]",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "a[6738] = '18:00'\ndf_heat['Time (HH:MM)'] = a \ndf_heat = df_heat.drop(['Timestamp'],axis = 1)\ndf_heat = df_heat.set_index('Time (HH:MM)')\nprint(df_heat)\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:2]\ndf = df[6734:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    ",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df_heat",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df_heat = df_heat.drop(['Timestamp'],axis = 1)\ndf_heat = df_heat.set_index('Time (HH:MM)')\nprint(df_heat)\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:2]\ndf = df[6734:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('5.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(5,5))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df_heat",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df_heat = df_heat.set_index('Time (HH:MM)')\nprint(df_heat)\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:2]\ndf = df[6734:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('5.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:3]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df_heat.iloc[:, 0:2]\ndf = df[6734:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('5.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:3]\ndf = df[6729:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    ",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df[6734:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('5.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:3]\ndf = df[6729:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "svm",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "svm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('5.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:3]\ndf = df[6729:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "figure",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "figure = svm.get_figure()    \nfigure.savefig('5.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(5,5))\ndf = df_heat.iloc[:, 0:3]\ndf = df[6729:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat.iloc[:, 0:4]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df_heat.iloc[:, 0:3]\ndf = df[6729:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat.iloc[:, 0:4]\ndf = df[6719:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    ",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df[6729:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat.iloc[:, 0:4]\ndf = df[6719:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "svm",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "svm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat.iloc[:, 0:4]\ndf = df[6719:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "figure",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "figure = svm.get_figure()    \nfigure.savefig('10.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat.iloc[:, 0:4]\ndf = df[6719:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6709:6739].astype(float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df_heat.iloc[:, 0:4]\ndf = df[6719:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6709:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df[6719:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6709:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "svm",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "svm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6709:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6689:6739].astype(float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "figure",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "figure = svm.get_figure()    \nfigure.savefig('20.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6709:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6689:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df_heat[6709:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6689:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('50.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "svm",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "svm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6689:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('50.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6639:6739].astype(float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "figure",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "figure = svm.get_figure()    \nfigure.savefig('30.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6689:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('50.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6639:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df_heat[6689:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('50.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6639:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('100.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "svm",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "svm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('50.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6639:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('100.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "figure",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "figure = svm.get_figure()    \nfigure.savefig('50.pdf', dpi=400,bbox_inches='tight')\nplt.figure(figsize=(10,5))\ndf = df_heat[6639:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('100.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "df = df_heat[6639:6739].astype(float)\nsvm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('100.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "svm",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "svm = sns.heatmap(df.T,cbar_kws={'label': 'Failure probability'})\nfigure = svm.get_figure()    \nfigure.savefig('100.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "figure",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "peekOfCode": "figure = svm.get_figure()    \nfigure.savefig('100.pdf', dpi=400,bbox_inches='tight')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Results_analysis.visualization.visualization",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Slurm_job_orchestration.generate_batch_scripts",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Slurm_job_orchestration.generate_batch_scripts",
        "peekOfCode": "folders = [0,10,12,14,16,18,2,21,23,25,27,29,30,32,34,36,38,40,42,44,46,48,6,8,\n           1,11,13,15,17,19,20,22,24,26,28,3,31,33,35,37,39,41,43,45,47,5,7,9]\nfor model in [\"dense_b_scripts\",\"dt_b_scripts\",\"gb_b_scripts\",\"GNN_b_scripts\",\"rf_b_scripts\"]:\n    os.mkdir(model)\nfor fw in [4,6,12,24,32,64,96,192,288]:\n    if((fw==4) or (fw==6) or (fw==12) or (fw==24)):\n        t = \"02:30:00\"\n    elif((fw==32) or (fw==64)):\n        t = \"03:30:00\"\n    else:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Slurm_job_orchestration.generate_batch_scripts",
        "documentation": {}
    },
    {
        "label": "get_node",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "peekOfCode": "def get_node(x):\n    tmp = x.split('/')\n    tmp = tmp[-1]\n    tmp = tmp.split('.')\n    return int(tmp[0])\ndef format_timestamp(ts):\n    tmp = str(ts)\n    tmp = datetime.strptime(tmp[:-6], \"%Y-%m-%d %H:%M:%S\")\n    tmp = tmp.strftime(\"%Y-%m-%d_%H:%M:%S\")\n    return tmp",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "documentation": {}
    },
    {
        "label": "format_timestamp",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "peekOfCode": "def format_timestamp(ts):\n    tmp = str(ts)\n    tmp = datetime.strptime(tmp[:-6], \"%Y-%m-%d %H:%M:%S\")\n    tmp = tmp.strftime(\"%Y-%m-%d_%H:%M:%S\")\n    return tmp\nfor fw in [4,6,12,24,32,64,96,192,288]:\n    dir_path = '{}'.format(fw)\n    files = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(dir_path) for f in filenames]\n    files = sorted(files, key = lambda x:get_node(x))\n    df = pd.read_parquet(files[0])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "documentation": {}
    },
    {
        "label": "save_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "peekOfCode": "save_path = LABELS_PATH\nif(os.path.exists(save_path)):\n    print('save path exits!')\nelse:\n    os.makedirs(save_path)\n    for FW in [4,6,12,24,32,64,96,192,288]:\n        os.makedirs(os.path.join(save_path,'{}'.format(FW)))\n    print(\"The new directory is created!\")\ndef get_node(x):\n    tmp = x.split('/')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.create_label_samples",
        "documentation": {}
    },
    {
        "label": "GCNDataManager",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gcn_manager",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gcn_manager",
        "peekOfCode": "class GCNDataManager:\n  \"\"\"\n  Class that loads and manages data to feed a GCN model.\n  \"\"\"\n  def __init__(self):\n    self.raw_data_path = RAW_DATA_PATH\n    self.samples_AP_path = BASE_AP_DATA_PATH\n    self.M100 = Marconi100Room(None)\n  def load_AP_samples(self, fw:int, idx:int):\n    with open(os.path.join(BASE_AP_DATA_PATH,\"{}/{}.pickle\".format(fw,idx)), 'rb') as f:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gcn_manager",
        "documentation": {}
    },
    {
        "label": "index_ranges",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_batch_files_sample_creation",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_batch_files_sample_creation",
        "peekOfCode": "index_ranges = []\nfor i in range(0,51037,500):\n    start_idx = i\n    end_idx = i + 500\n    index_ranges.append((start_idx,end_idx))\ndel index_ranges[-1]\nindex_ranges.append((51000, 51037))\nos.mkdir('samples_batch_files')\nfor fw in [4,6,12,24,32,64,96,192,288]:\n    for idx in index_ranges:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_batch_files_sample_creation",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "def new_label_creation(df: pd.DataFrame, t_n: int) -> pd.DataFrame:\n  \"\"\"\n  Create new_labels for anomaly anticipation for future window (t_n). The algorithm looks\n  for an anomaly in the next t_n timesteps. The current timestep is said to be an anomaly\n  if atleast one anomaly ahead in the future window (t_n)\n  \"\"\"\n  value = df['state'].to_numpy()\n  new_label = []\n  for i in range(len(value)):\n      anomaly_ahead = False",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "def read_file(node_dir):\n    \"\"\" Read the node's parquet files \"\"\"\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna(subset = ['state'])\n    return node_data\nprint(\"Generating new labels\")\nprint(\"******************************\")\nnew_label_path = os.path.exists(new_label_data_path)\nif not new_label_path:\n   # Create a new directory because it does not exist",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "inpts = sys.argv\nfw = int(inpts[1])\ndir_path = RAW_DATA_PATH\nnew_label_data_path = RAW_NEW_LABEL_DATA_PATH\ndef new_label_creation(df: pd.DataFrame, t_n: int) -> pd.DataFrame:\n  \"\"\"\n  Create new_labels for anomaly anticipation for future window (t_n). The algorithm looks\n  for an anomaly in the next t_n timesteps. The current timestep is said to be an anomaly\n  if atleast one anomaly ahead in the future window (t_n)\n  \"\"\"",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "fw = int(inpts[1])\ndir_path = RAW_DATA_PATH\nnew_label_data_path = RAW_NEW_LABEL_DATA_PATH\ndef new_label_creation(df: pd.DataFrame, t_n: int) -> pd.DataFrame:\n  \"\"\"\n  Create new_labels for anomaly anticipation for future window (t_n). The algorithm looks\n  for an anomaly in the next t_n timesteps. The current timestep is said to be an anomaly\n  if atleast one anomaly ahead in the future window (t_n)\n  \"\"\"\n  value = df['state'].to_numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "dir_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "dir_path = RAW_DATA_PATH\nnew_label_data_path = RAW_NEW_LABEL_DATA_PATH\ndef new_label_creation(df: pd.DataFrame, t_n: int) -> pd.DataFrame:\n  \"\"\"\n  Create new_labels for anomaly anticipation for future window (t_n). The algorithm looks\n  for an anomaly in the next t_n timesteps. The current timestep is said to be an anomaly\n  if atleast one anomaly ahead in the future window (t_n)\n  \"\"\"\n  value = df['state'].to_numpy()\n  new_label = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "new_label_data_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "new_label_data_path = RAW_NEW_LABEL_DATA_PATH\ndef new_label_creation(df: pd.DataFrame, t_n: int) -> pd.DataFrame:\n  \"\"\"\n  Create new_labels for anomaly anticipation for future window (t_n). The algorithm looks\n  for an anomaly in the next t_n timesteps. The current timestep is said to be an anomaly\n  if atleast one anomaly ahead in the future window (t_n)\n  \"\"\"\n  value = df['state'].to_numpy()\n  new_label = []\n  for i in range(len(value)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "new_label_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "new_label_path = os.path.exists(new_label_data_path)\nif not new_label_path:\n   # Create a new directory because it does not exist\n   os.makedirs(new_label_data_path)\n   for FW in [4,6,12,24,32,64,96,192,288]:\n      os.makedirs(os.path.join(new_label_data_path,'{}'.format(FW)))\n   print(\"The new directory is created!\")\n#reading files from data directory\nfiles = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(dir_path) for f in filenames]\nprint(\"Total files: \",len(files))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "peekOfCode": "files = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(dir_path) for f in filenames]\nprint(\"Total files: \",len(files))\nprint(\"\\nFW : {}\".format(fw))\nfor node_file in files:\n    df = read_file(node_file)\n    df['state'] = df['state'].replace(2,1)\n    df['state'] = df['state'].replace(3,1)\n    df = new_label_creation(df, fw)\n    tmp = node_file.split(\"/\")\n    tmp = tmp[-1]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.gen_new_label",
        "documentation": {}
    },
    {
        "label": "arr",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.job_submit_txt",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.job_submit_txt",
        "peekOfCode": "arr = os.listdir('samples_batch_files/')\nprint(len(arr))\ns = ''\nfor i in arr:\n    s = s + 'sbatch {};'.format(i)\nprint(s)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.job_submit_txt",
        "documentation": {}
    },
    {
        "label": "s",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.job_submit_txt",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.job_submit_txt",
        "peekOfCode": "s = ''\nfor i in arr:\n    s = s + 'sbatch {};'.format(i)\nprint(s)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.job_submit_txt",
        "documentation": {}
    },
    {
        "label": "Marconi100Room",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.room",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.room",
        "peekOfCode": "class Marconi100Room:\n  \"\"\"\n  Class representing the Marconi 100 (M100) room and its nodes distribution.\n  Upon initialization, the class creates the `self.room_grid` member. It\n  represents a 3D spatial grid of nodes, with each entry being the integer ID\n  for one node. -1 is not a node, but rather a placeholder for an empty slot in\n  the room.\n  See also https://gitlab.com/ecs-lab/exadata/-/blob/main/documentation/racks_spatial_distribution.md\n  The above layout is the default one, but a different layout can be provided\n  via the `racks_layout` argument.",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.room",
        "documentation": {}
    },
    {
        "label": "AnomalyPredictionGraphDataset",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "peekOfCode": "class AnomalyPredictionGraphDataset(Dataset):\n    def __init__(self,manager: GCNDataManager):\n        self.data_path = BASE_DATA_PATH\n        self.eligible_ts_file = os.path.join(RESOURCES_PATH,\"eligible_ts.pickle\")\n        self.col_list_nw_file = os.path.join(RESOURCES_PATH,\"col_list_node_wise.pickle\")\n        self.M100 = Marconi100Room(None)\n        self.manager = manager\n        self.edges_file = os.path.join(RESOURCES_PATH, 'edges.csv')\n        self.weights_file = os.path.join(RESOURCES_PATH, 'weights.csv')\n        if(os.path.isfile(self.edges_file)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "peekOfCode": "inpts = sys.argv\nstart_idx = int(inpts[1])\nend_idx = int(inpts[2])\nclass AnomalyPredictionGraphDataset(Dataset):\n    def __init__(self,manager: GCNDataManager):\n        self.data_path = BASE_DATA_PATH\n        self.eligible_ts_file = os.path.join(RESOURCES_PATH,\"eligible_ts.pickle\")\n        self.col_list_nw_file = os.path.join(RESOURCES_PATH,\"col_list_node_wise.pickle\")\n        self.M100 = Marconi100Room(None)\n        self.manager = manager",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "documentation": {}
    },
    {
        "label": "start_idx",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "peekOfCode": "start_idx = int(inpts[1])\nend_idx = int(inpts[2])\nclass AnomalyPredictionGraphDataset(Dataset):\n    def __init__(self,manager: GCNDataManager):\n        self.data_path = BASE_DATA_PATH\n        self.eligible_ts_file = os.path.join(RESOURCES_PATH,\"eligible_ts.pickle\")\n        self.col_list_nw_file = os.path.join(RESOURCES_PATH,\"col_list_node_wise.pickle\")\n        self.M100 = Marconi100Room(None)\n        self.manager = manager\n        self.edges_file = os.path.join(RESOURCES_PATH, 'edges.csv')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "documentation": {}
    },
    {
        "label": "end_idx",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "peekOfCode": "end_idx = int(inpts[2])\nclass AnomalyPredictionGraphDataset(Dataset):\n    def __init__(self,manager: GCNDataManager):\n        self.data_path = BASE_DATA_PATH\n        self.eligible_ts_file = os.path.join(RESOURCES_PATH,\"eligible_ts.pickle\")\n        self.col_list_nw_file = os.path.join(RESOURCES_PATH,\"col_list_node_wise.pickle\")\n        self.M100 = Marconi100Room(None)\n        self.manager = manager\n        self.edges_file = os.path.join(RESOURCES_PATH, 'edges.csv')\n        self.weights_file = os.path.join(RESOURCES_PATH, 'weights.csv')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.torch_gcn_dataset",
        "documentation": {}
    },
    {
        "label": "get_ts",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.train_val_test_split",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.train_val_test_split",
        "peekOfCode": "def get_ts(x):\n    tmp = x.split('/')\n    tmp = tmp[-1]\n    tmp = tmp.split('.')\n    return tmp[0]\nfor fw in [4,6,12,24,32,64,96,192,288]:\n    files = []\n    # loop over the contents of the directory\n    for filename in os.listdir(os.path.join(data_path,\"{}\".format(fw))):\n        # construct the full path of the file",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.train_val_test_split",
        "documentation": {}
    },
    {
        "label": "data_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.train_val_test_split",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.train_val_test_split",
        "peekOfCode": "data_path = BASE_AP_DATA_PATH\ndef get_ts(x):\n    tmp = x.split('/')\n    tmp = tmp[-1]\n    tmp = tmp.split('.')\n    return tmp[0]\nfor fw in [4,6,12,24,32,64,96,192,288]:\n    files = []\n    # loop over the contents of the directory\n    for filename in os.listdir(os.path.join(data_path,\"{}\".format(fw))):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.train_val_test_split",
        "documentation": {}
    },
    {
        "label": "AP_train_validaion_Dataset",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "peekOfCode": "class AP_train_validaion_Dataset(Dataset):\n  \"\"\"PyTorch dataset class for M100 training data.\n  This simple class is needed to perform batch training of the GCN model.\n  Like all `Dataset` classes, it can be given to a `DataLoader` object which in\n  turn can be looped on in order to get training batches.\n  \"\"\"\n  def __init__(self, task:str):\n    self.task = task\n    if(self.task == 'train'):\n        self.data_path = os.path.join(BASE_AP_DATA_PATH,\"{}/train\".format(fw))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "documentation": {}
    },
    {
        "label": "GCN_anomaly_anticipation",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "peekOfCode": "class GCN_anomaly_anticipation(torch.nn.Module):\n  def __init__(self, in_channels, out_channels):\n      super().__init__()\n      #encoder\n      self.conv1 = GCNConv(in_channels, 300)\n      self.conv2 = GCNConv(300, 100)\n      self.conv3 = GCNConv(100, out_channels)\n      #dense layer\n      self.fc1 = torch.nn.Linear(out_channels,16)\n      self.fc2 = torch.nn.Linear(16,1)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "peekOfCode": "inpts = sys.argv\nfw = int(inpts[1])\nexperiment = str(inpts[2])\nclass AP_train_validaion_Dataset(Dataset):\n  \"\"\"PyTorch dataset class for M100 training data.\n  This simple class is needed to perform batch training of the GCN model.\n  Like all `Dataset` classes, it can be given to a `DataLoader` object which in\n  turn can be looped on in order to get training batches.\n  \"\"\"\n  def __init__(self, task:str):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "documentation": {}
    },
    {
        "label": "fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "peekOfCode": "fw = int(inpts[1])\nexperiment = str(inpts[2])\nclass AP_train_validaion_Dataset(Dataset):\n  \"\"\"PyTorch dataset class for M100 training data.\n  This simple class is needed to perform batch training of the GCN model.\n  Like all `Dataset` classes, it can be given to a `DataLoader` object which in\n  turn can be looped on in order to get training batches.\n  \"\"\"\n  def __init__(self, task:str):\n    self.task = task",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "documentation": {}
    },
    {
        "label": "experiment",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "peekOfCode": "experiment = str(inpts[2])\nclass AP_train_validaion_Dataset(Dataset):\n  \"\"\"PyTorch dataset class for M100 training data.\n  This simple class is needed to perform batch training of the GCN model.\n  Like all `Dataset` classes, it can be given to a `DataLoader` object which in\n  turn can be looped on in order to get training batches.\n  \"\"\"\n  def __init__(self, task:str):\n    self.task = task\n    if(self.task == 'train'):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.training_gcn_dataset ",
        "documentation": {}
    },
    {
        "label": "min_max_scalar",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)\n  max_values, _ = torch.max(tensor, dim=0)\n  # Perform min-max scaling\n  normalized_tensor = (tensor - min_values) / (max_values - min_values)\n  return normalized_tensor\ndef z_score_normalization(tensor):\n  # Normalize input features using z-score normalization\n  feature_scaler = StandardScaler()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "z_score_normalization",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def z_score_normalization(tensor):\n  # Normalize input features using z-score normalization\n  feature_scaler = StandardScaler()\n  # Reshape the entire tensor to (n_samples, n_features)\n  reshaped_features = tensor.reshape(-1, tensor.size(1))\n  # Apply normalization to the reshaped tensor\n  normalized_features = torch.tensor(feature_scaler.fit_transform(reshaped_features),dtype=torch.float32)\n  # Reshape the normalized tensor back to its original shape\n  tensor.x = normalized_features.reshape(tensor.size())\n  return tensor",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "get_ts",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def get_ts(x):\n  tmp = x.split('/')\n  tmp = tmp[-1]\n  tmp = tmp.split('.')\n  return tmp[0]\ndef get_files_path(dir_path:str) ->list:\n  files = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(dir_path) for f in filenames]\n  files = sorted(files, key = lambda x:get_ts(x))\n  return files\ndef convert_na_to_nan(value):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "get_files_path",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def get_files_path(dir_path:str) ->list:\n  files = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(dir_path) for f in filenames]\n  files = sorted(files, key = lambda x:get_ts(x))\n  return files\ndef convert_na_to_nan(value):\n  return np.nan if pd.isna(value) else value\ndef get_eligible_list() -> list:\n  print(\"Generating Eligible TS list.....\")\n  file_path = os.path.join(RAW_NEW_LABEL_DATA_PATH,'4/0.parquet')\n  node_data = pd.read_parquet(file_path)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "convert_na_to_nan",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def convert_na_to_nan(value):\n  return np.nan if pd.isna(value) else value\ndef get_eligible_list() -> list:\n  print(\"Generating Eligible TS list.....\")\n  file_path = os.path.join(RAW_NEW_LABEL_DATA_PATH,'4/0.parquet')\n  node_data = pd.read_parquet(file_path)\n  ts_list = node_data['timestamp']\n  split_list = []\n  for ts in ts_list:\n    tmp = str(ts)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "get_eligible_list",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def get_eligible_list() -> list:\n  print(\"Generating Eligible TS list.....\")\n  file_path = os.path.join(RAW_NEW_LABEL_DATA_PATH,'4/0.parquet')\n  node_data = pd.read_parquet(file_path)\n  ts_list = node_data['timestamp']\n  split_list = []\n  for ts in ts_list:\n    tmp = str(ts)\n    tmp = datetime.strptime(tmp[:-6], \"%Y-%m-%d %H:%M:%S\")\n    tmp = tmp.strftime(\"%Y-%m-%d_%H:%M:%S\")",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "node_wise_col_list",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def node_wise_col_list() ->list:\n  print(\"Generating Node-Wise Columns list.....\")\n  col_list = []\n  for i in range(980):\n    df = pd.read_parquet(os.path.join(RAW_DATA_PATH,\"{}.parquet\".format(i)))\n    col_list.append(list(df.columns))\n  print(\"DONE!\")\n  with open(os.path.join(RESOURCES_PATH,'col_list_node_wise.pickle'),'wb') as f:\n    pickle.dump(col_list,f)\n  return col_list",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "line_graph_edges",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def line_graph_edges() -> list:\n    edges = []\n    for j in range(49):\n        for i in range(20):\n            temp = []\n            node = i+(j*20)\n            if i == 0:\n                temp.append([node,node+1])\n            elif i == 20-1:\n                temp.append([node,node-1])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def classification_report(ground_truths,predictions):\n  # Define a range of threshold values to explore\n  thresholds = np.arange(0.1, 1.0, 0.05)\n  best_threshold = 0.0\n  best_f1_score = 0.0\n  for threshold in thresholds:\n    predicted_labels = [1 if prob >= threshold else 0 for prob in predictions]\n    f1 = f1_score(ground_truths, predicted_labels)\n    if f1 > best_f1_score:\n      best_f1_score = f1",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "get_min_samples",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def get_min_samples(root: str) -> int:\n  no_of_samples = []\n  for fw in [4,6,12,24,32,64,96,192,288]:\n    dir_path = os.path.join(root,'{}/'.format(fw))\n    files = []\n    # loop over the contents of the directory\n    for filename in os.listdir(os.path.join(dir_path.format(fw))):\n      # construct the full path of the file\n      file_path = os.path.join(dir_path, filename)\n      # check if the file is a regular file (not a directory)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "get_column_names",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "def get_column_names(root: str) -> list[str]:\n    files = []\n    # loop over the contents of the directory\n    for filename in os.listdir(root):\n        # construct the full path of the file\n        file_path = os.path.join(root, filename)\n        # check if the file is a regular file (not a directory)\n        if os.path.isfile(file_path):\n            files.append(file_path)\n    DATA = pd.read_parquet(files[0])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "BASE_AP_DATA_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "BASE_AP_DATA_PATH = \"\"          # add here the generated samples path\nBASE_DATA_PATH = \"\"             # add here the base samples path (aggregated data -> nodes as rows and metrics as col)\nRAW_DATA_PATH = \"\"              # add here the raw data path (aggregated data -> timestamps as rows and metrics as col)\nRAW_NEW_LABEL_DATA_PATH = \"\"    # add here the raw new label data path (path where the new labels are constructed)\nRESOURCES_PATH = \"resources\"\nRESULTS_PATH = \"results\"\nLABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "BASE_DATA_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "BASE_DATA_PATH = \"\"             # add here the base samples path (aggregated data -> nodes as rows and metrics as col)\nRAW_DATA_PATH = \"\"              # add here the raw data path (aggregated data -> timestamps as rows and metrics as col)\nRAW_NEW_LABEL_DATA_PATH = \"\"    # add here the raw new label data path (path where the new labels are constructed)\nRESOURCES_PATH = \"resources\"\nRESULTS_PATH = \"results\"\nLABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "RAW_DATA_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "RAW_DATA_PATH = \"\"              # add here the raw data path (aggregated data -> timestamps as rows and metrics as col)\nRAW_NEW_LABEL_DATA_PATH = \"\"    # add here the raw new label data path (path where the new labels are constructed)\nRESOURCES_PATH = \"resources\"\nRESULTS_PATH = \"results\"\nLABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "RAW_NEW_LABEL_DATA_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "RAW_NEW_LABEL_DATA_PATH = \"\"    # add here the raw new label data path (path where the new labels are constructed)\nRESOURCES_PATH = \"resources\"\nRESULTS_PATH = \"results\"\nLABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "RESOURCES_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "RESOURCES_PATH = \"resources\"\nRESULTS_PATH = \"results\"\nLABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "RESULTS_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "RESULTS_PATH = \"results\"\nLABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "LABELS_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "LABELS_PATH = \"\"                # add here the path to the label samples that are created from the raw new label data\nSAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "SAMPLES_SAVE_PATH",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "SAMPLES_SAVE_PATH = \"\"          # add here the path where you want to save the samples\nBATCH_SIZE= 32\nNUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)\n  max_values, _ = torch.max(tensor, dim=0)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "NUM_EPOCHS",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "NUM_EPOCHS = 20\nLEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)\n  max_values, _ = torch.max(tensor, dim=0)\n  # Perform min-max scaling\n  normalized_tensor = (tensor - min_values) / (max_values - min_values)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "LEARNING_RATE",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "LEARNING_RATE = 0.001\nOPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)\n  max_values, _ = torch.max(tensor, dim=0)\n  # Perform min-max scaling\n  normalized_tensor = (tensor - min_values) / (max_values - min_values)\n  return normalized_tensor",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "OPTIMIZER",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "OPTIMIZER = \"Adam\"\nCRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)\n  max_values, _ = torch.max(tensor, dim=0)\n  # Perform min-max scaling\n  normalized_tensor = (tensor - min_values) / (max_values - min_values)\n  return normalized_tensor\ndef z_score_normalization(tensor):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "CRITERION",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "peekOfCode": "CRITERION = \"BCEwithLogits\"\ndef min_max_scalar(tensor):\n  # Calculate min and max values column-wise\n  min_values, _ = torch.min(tensor, dim=0)\n  max_values, _ = torch.max(tensor, dim=0)\n  # Perform min-max scaling\n  normalized_tensor = (tensor - min_values) / (max_values - min_values)\n  return normalized_tensor\ndef z_score_normalization(tensor):\n  # Normalize input features using z-score normalization",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.Room-gnn.utils",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "def read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "feature_and_new_label_extract",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "def feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()\n    test_feat = torch.tensor(test_feat, dtype=torch.float)\n    train_label = train_df['new_label']\n    train_label = train_label.to_numpy()\n    train_label = torch.tensor(train_label, dtype=torch.float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "def create_dataset(train_x,test_x,train_y,test_y):\n    train_data = []\n    for i in range(train_x.shape[0]):\n        train_data.append([train_x[i],train_y[i]])\n    test_data = []\n    for i in range(test_x.shape[0]):\n        test_data.append([test_x[i],test_y[i]])\n    return train_data,test_data\ndef new_label_creation(df):\n    new_label = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "def new_label_creation(df):\n    new_label = []\n    for i in range(df.shape[0]):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=df.shape[0]):\n                break\n            else: \n                if(df['value'][j]==1):\n                    anomaly_ahead = True",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "inpts = sys.argv\nrack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "rack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "t_n",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "t_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "ln",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "ln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "anticipation",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "anticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "n_rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "n_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "dir_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "dir_path = 'data/{}/'.format(rack)\nfiles = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "peekOfCode": "files = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)\nfor i in range(len(files)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.DT",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "def read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "feature_and_new_label_extract",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "def feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()\n    test_feat = torch.tensor(test_feat, dtype=torch.float)\n    train_label = train_df['new_label']\n    train_label = train_label.to_numpy()\n    train_label = torch.tensor(train_label, dtype=torch.float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "def create_dataset(train_x,test_x,train_y,test_y):\n    train_data = []\n    for i in range(train_x.shape[0]):\n        train_data.append([train_x[i],train_y[i]])\n    test_data = []\n    for i in range(test_x.shape[0]):\n        test_data.append([test_x[i],test_y[i]])\n    return train_data,test_data\ndef new_label_creation(df):\n    new_label = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "def new_label_creation(df):\n    new_label = []\n    for i in range(df.shape[0]):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=df.shape[0]):\n                break\n            else: \n                if(df['value'][j]==1):\n                    anomaly_ahead = True",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "inpts = sys.argv\nrack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "rack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "t_n",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "t_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "ln",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "ln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "anticipation",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "anticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "n_rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "n_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "dir_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "dir_path = 'data/{}/'.format(rack)\nfiles = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "peekOfCode": "files = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)\nfor i in range(len(files)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GB",
        "documentation": {}
    },
    {
        "label": "anomaly_anticipation",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "class anomaly_anticipation(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        #encoder\n        self.conv1 = GCNConv(in_channels, 300)\n        self.conv2 = GCNConv(300, 100)\n        self.conv3 = GCNConv(100, out_channels)\n        #dense layer\n        self.fc1 = torch.nn.Linear(out_channels,16)\n        self.fc2 = torch.nn.Linear(16,1)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "def read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef new_label_creation(df):\n    new_label = []\n    for i in range(df.shape[0]):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=df.shape[0]):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "def new_label_creation(df):\n    new_label = []\n    for i in range(df.shape[0]):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=df.shape[0]):\n                break\n            else: \n                if(df['value'][j]==1):\n                    anomaly_ahead = True",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "feature_extraction",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "def feature_extraction(df):\n    if(anticipation):\n        df_feat = df.drop(columns=['new_label'])\n    else:\n        pass\n    df_feat = df_feat.to_numpy()\n    df_feat = torch.tensor(df_feat, dtype=torch.float)\n    return df_feat\ndef labels_extraction(df):\n    if(anticipation):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "labels_extraction",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "def labels_extraction(df):\n    if(anticipation):\n        df_labels = df[['new_label']]\n    else:\n        pass\n    df_labels = df_labels.to_numpy()\n    df_labels = torch.tensor(df_labels, dtype=torch.float)\n    return df_labels\nclass anomaly_anticipation(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "def train():\n    model.train()\n    for d in loader:\n        d = d.to(device)\n        optimizer.zero_grad()\n        out = model(d.x,d.edge_index)\n        loss = criterion(out, d.y)\n        loss.backward()\n        optimizer.step()\n    return float(loss)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "inpts = sys.argv\nrack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "rack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "t_n",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "t_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "ln",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "ln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "anticipation",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "anticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef new_label_creation(df):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "n_rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "n_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef new_label_creation(df):\n    new_label = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "dir_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "dir_path = 'data/{}/'.format(rack)\nfiles = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\n#checking GPU",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "files = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\n#checking GPU\nprint(device)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "len_nodes",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "len_nodes = []\nnode_start = 0\nDATA = read_file(files[0])\nlen_nodes.append((node_start,node_start + DATA.shape[0]))\nnode_start = node_start + DATA.shape[0]\nfor i in range(1,len(files)):\n    data = read_file(files[i])\n    len_nodes.append((node_start,node_start + data.shape[0]))\n    node_start = node_start + data.shape[0]\n    DATA = DATA.append(data)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "node_start",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "node_start = 0\nDATA = read_file(files[0])\nlen_nodes.append((node_start,node_start + DATA.shape[0]))\nnode_start = node_start + DATA.shape[0]\nfor i in range(1,len(files)):\n    data = read_file(files[i])\n    len_nodes.append((node_start,node_start + data.shape[0]))\n    node_start = node_start + data.shape[0]\n    DATA = DATA.append(data)\nDATA.reset_index(drop=True, inplace = True)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA = read_file(files[0])\nlen_nodes.append((node_start,node_start + DATA.shape[0]))\nnode_start = node_start + DATA.shape[0]\nfor i in range(1,len(files)):\n    data = read_file(files[i])\n    len_nodes.append((node_start,node_start + data.shape[0]))\n    node_start = node_start + data.shape[0]\n    DATA = DATA.append(data)\nDATA.reset_index(drop=True, inplace = True)\nDATA = DATA.fillna(0)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "node_start",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "node_start = node_start + DATA.shape[0]\nfor i in range(1,len(files)):\n    data = read_file(files[i])\n    len_nodes.append((node_start,node_start + data.shape[0]))\n    node_start = node_start + data.shape[0]\n    DATA = DATA.append(data)\nDATA.reset_index(drop=True, inplace = True)\nDATA = DATA.fillna(0)\nDATA = DATA.drop(columns=['timestamp'])\nDATA = DATA.astype(float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA = DATA.fillna(0)\nDATA = DATA.drop(columns=['timestamp'])\nDATA = DATA.astype(float)\nDATA['value'] = DATA['value'].replace(2,1)\nDATA['value'] = DATA['value'].replace(3,1)\nscaler = preprocessing.MinMaxScaler()\nnames = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA = DATA.drop(columns=['timestamp'])\nDATA = DATA.astype(float)\nDATA['value'] = DATA['value'].replace(2,1)\nDATA['value'] = DATA['value'].replace(3,1)\nscaler = preprocessing.MinMaxScaler()\nnames = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA = DATA.astype(float)\nDATA['value'] = DATA['value'].replace(2,1)\nDATA['value'] = DATA['value'].replace(3,1)\nscaler = preprocessing.MinMaxScaler()\nnames = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA['value']",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA['value'] = DATA['value'].replace(2,1)\nDATA['value'] = DATA['value'].replace(3,1)\nscaler = preprocessing.MinMaxScaler()\nnames = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []\ni = 0",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA['value']",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA['value'] = DATA['value'].replace(3,1)\nscaler = preprocessing.MinMaxScaler()\nnames = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []\ni = 0\nfor j in range(len(files)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "scaler = preprocessing.MinMaxScaler()\nnames = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []\ni = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "names",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "names = DATA.columns\nd = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []\ni = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]\n    df.reset_index(drop=True, inplace = True)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "d = scaler.fit_transform(DATA)\nDATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []\ni = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "DATA",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "DATA = pd.DataFrame(d, columns=names)\nprint(DATA.shape)\nrack = []\nnode = []\ni = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)\n    node.append(df)   ",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "rack = []\nnode = []\ni = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)\n    node.append(df)   \n    rack.append(node)\n    node = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "node",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "node = []\ni = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)\n    node.append(df)   \n    rack.append(node)\n    node = []\nprint(len(rack))",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "i",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "i = 0\nfor j in range(len(files)):\n    df = DATA[len_nodes[j][0]:len_nodes[j][1]]\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)\n    node.append(df)   \n    rack.append(node)\n    node = []\nprint(len(rack))\nnode_names = [f.strip('data//.parquet') for f in files]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "node_names",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "node_names = [f.strip('data//.parquet') for f in files]\nprint(node_names)\nprint('len',ln)\nnode_names = [int(f[ln+1:]) for f in node_names]\nprint(node_names)\nsorted_rack = sorted(zip(node_names,rack))\nprint(files)\nprint([t[0] for t in sorted_rack])\nrack = [t[1] for t in sorted_rack]\n#anticipation label pre-processing",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "node_names",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "node_names = [int(f[ln+1:]) for f in node_names]\nprint(node_names)\nsorted_rack = sorted(zip(node_names,rack))\nprint(files)\nprint([t[0] for t in sorted_rack])\nrack = [t[1] for t in sorted_rack]\n#anticipation label pre-processing\nif(anticipation):\n    for i in range(len(rack)):\n        for j in range(len(rack[i])):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "sorted_rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "sorted_rack = sorted(zip(node_names,rack))\nprint(files)\nprint([t[0] for t in sorted_rack])\nrack = [t[1] for t in sorted_rack]\n#anticipation label pre-processing\nif(anticipation):\n    for i in range(len(rack)):\n        for j in range(len(rack[i])):\n            new_label_creation(rack[i][j])\n    print(\"Before : \")",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "rack = [t[1] for t in sorted_rack]\n#anticipation label pre-processing\nif(anticipation):\n    for i in range(len(rack)):\n        for j in range(len(rack[i])):\n            new_label_creation(rack[i][j])\n    print(\"Before : \")\n    print(rack[0][0]['value'].value_counts())\n    print(\"After : \")\n    print(rack[0][0]['new_label'].value_counts())",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "rack_split",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "rack_split = []\nfor i in range(len(rack)):\n    node_split = []\n    for j in range(len(rack[i])):\n        data = {\n            \"train\": rack[i][j][:int(rack[i][j].shape[0]*0.8)],\n            \"test\": rack[i][j][int(rack[i][j].shape[0]*0.8):],\n        }\n        node_split.append(data)\n    rack_split.append(node_split)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "rack_feats_labels",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "rack_feats_labels = []\nfor i in range(len(rack_split)):\n    node_feats_labels = []\n    for j in range(len(rack_split[i])):\n        train_feat = feature_extraction(rack_split[i][j]['train'])\n        train_label = labels_extraction(rack_split[i][j]['train'])\n        test_feat = feature_extraction(rack_split[i][j]['test'])\n        test_label = labels_extraction(rack_split[i][j]['test'])\n        data = {\n            \"train_feat\": train_feat,",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "edges",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "edges = []\nk = 0\nfor i in range(len(files)):\n    temp = []\n    if i == 0:\n        temp.append([i,i+1])\n    elif i == len(files)-1:\n        temp.append([i,i-1])\n    else:\n        temp.append([i,i-1])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "k",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "k = 0\nfor i in range(len(files)):\n    temp = []\n    if i == 0:\n        temp.append([i,i+1])\n    elif i == len(files)-1:\n        temp.append([i,i-1])\n    else:\n        temp.append([i,i-1])\n        temp.append([i,i+1])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "edges",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "edges = torch.tensor(edges, dtype=torch.long)\nprint(edges.t().contiguous())\ntrain_min = len(rack_feats_labels[0][0]['train_feat'])\nfor i in range(len(rack_feats_labels)):\n    for j in range(len(rack_feats_labels[i])):\n        temp = len(rack_feats_labels[i][j]['train_feat'])\n        #print(temp)\n        if(temp<train_min):\n            train_min = temp\nprint(train_min)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "train_min",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "train_min = len(rack_feats_labels[0][0]['train_feat'])\nfor i in range(len(rack_feats_labels)):\n    for j in range(len(rack_feats_labels[i])):\n        temp = len(rack_feats_labels[i][j]['train_feat'])\n        #print(temp)\n        if(temp<train_min):\n            train_min = temp\nprint(train_min)\ntest_min = len(rack_feats_labels[0][0]['test_feat'])\nfor i in range(len(rack_feats_labels)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "test_min",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "test_min = len(rack_feats_labels[0][0]['test_feat'])\nfor i in range(len(rack_feats_labels)):\n    for j in range(len(rack_feats_labels[i])):\n        temp = len(rack_feats_labels[i][j]['test_feat'])\n        #print(temp)\n        if(temp<test_min):\n            test_min = temp\nprint(test_min)\ndata_list = []\nfor k in range(train_min):              # k is the timestamp",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "data_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "data_list = []\nfor k in range(train_min):              # k is the timestamp\n    g_x = []\n    g_y = []\n    for i in range(len(rack_feats_labels)):\n        for j in range(len(rack_feats_labels[i])):\n            g_x.append(rack_feats_labels[i][j]['train_feat'][k])\n            g_y.append(rack_feats_labels[i][j]['train_labels'][k])\n    g_x = torch.stack(g_x)\n    g_y = torch.stack(g_y)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "test_data_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "test_data_list = []\nfor k in range(test_min):              # k is the timestamp\n    g_x = []\n    g_y = []\n    for i in range(len(rack_feats_labels)):\n        for j in range(len(rack_feats_labels[i])):\n            g_x.append(rack_feats_labels[i][j]['test_feat'][k])\n            g_y.append(rack_feats_labels[i][j]['test_labels'][k])\n    g_x = torch.stack(g_x)\n    g_y = torch.stack(g_y)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "loader",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "loader = DataLoader(data_list, batch_size = 16, shuffle = False)\ntest_loader = DataLoader(test_data_list, shuffle = False)\nin_channels, out_channels = data.num_node_features, 16\nmodel = anomaly_anticipation(in_channels, out_channels)\nprint(model)\nmodel = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\n# Early stopping\nlast_loss = 100",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "test_loader = DataLoader(test_data_list, shuffle = False)\nin_channels, out_channels = data.num_node_features, 16\nmodel = anomaly_anticipation(in_channels, out_channels)\nprint(model)\nmodel = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\n# Early stopping\nlast_loss = 100\npatience = 2",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "model = anomaly_anticipation(in_channels, out_channels)\nprint(model)\nmodel = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\n# Early stopping\nlast_loss = 100\npatience = 2\ntrigger_times = 0\nEARLY_STOPPING = False",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "model = model.to(device)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\n# Early stopping\nlast_loss = 100\npatience = 2\ntrigger_times = 0\nEARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\n# Early stopping\nlast_loss = 100\npatience = 2\ntrigger_times = 0\nEARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()\n    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "criterion = torch.nn.BCEWithLogitsLoss()\n# Early stopping\nlast_loss = 100\npatience = 2\ntrigger_times = 0\nEARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()\n    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n    if loss > last_loss:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "last_loss",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "last_loss = 100\npatience = 2\ntrigger_times = 0\nEARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()\n    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n    if loss > last_loss:\n        trigger_times += 1\n        print('Trigger Times:', trigger_times)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "patience",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "patience = 2\ntrigger_times = 0\nEARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()\n    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n    if loss > last_loss:\n        trigger_times += 1\n        print('Trigger Times:', trigger_times)\n        if trigger_times >= patience:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "trigger_times",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "trigger_times = 0\nEARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()\n    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n    if loss > last_loss:\n        trigger_times += 1\n        print('Trigger Times:', trigger_times)\n        if trigger_times >= patience:\n            EARLY_STOPPING = True",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "EARLY_STOPPING",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "EARLY_STOPPING = False\nfor epoch in range(30):\n    loss = train()\n    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n    if loss > last_loss:\n        trigger_times += 1\n        print('Trigger Times:', trigger_times)\n        if trigger_times >= patience:\n            EARLY_STOPPING = True\n            print('Early stopping!')",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "loss",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "loss = []\npred_list = []\ny_true = []\nfor d in test_loader:\n    d = d.to(device)\n    out = model(d.x,d.edge_index)\n    pred = torch.sigmoid(out)\n    pred_list.append(pred)\n    y_true.append(d.y.detach().cpu().numpy())\nfor i in range(len(pred_list)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "pred_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "pred_list = []\ny_true = []\nfor d in test_loader:\n    d = d.to(device)\n    out = model(d.x,d.edge_index)\n    pred = torch.sigmoid(out)\n    pred_list.append(pred)\n    y_true.append(d.y.detach().cpu().numpy())\nfor i in range(len(pred_list)):\n    pred_list[i] = pred_list[i].detach().cpu().numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "y_true",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "y_true = []\nfor d in test_loader:\n    d = d.to(device)\n    out = model(d.x,d.edge_index)\n    pred = torch.sigmoid(out)\n    pred_list.append(pred)\n    y_true.append(d.y.detach().cpu().numpy())\nfor i in range(len(pred_list)):\n    pred_list[i] = pred_list[i].detach().cpu().numpy()\ny_true = [item for sublist in y_true for item in sublist]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "y_true",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "y_true = [item for sublist in y_true for item in sublist]\ny_true = [int(item) for item in y_true]\npred_list = [item for sublist in pred_list for item in sublist]\npred_list = [float(item) for item in pred_list]\nlen(y_true),len(pred_list)\nerror_df = pd.DataFrame({'prob': pred_list,\n                        'true_class': y_true})\nprint(n_rack)\nfilename = 'results/{}/{}_{}.pickle'.format(t_n,n_rack,t_n)\nwith open(filename, 'wb') as f:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "y_true",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "y_true = [int(item) for item in y_true]\npred_list = [item for sublist in pred_list for item in sublist]\npred_list = [float(item) for item in pred_list]\nlen(y_true),len(pred_list)\nerror_df = pd.DataFrame({'prob': pred_list,\n                        'true_class': y_true})\nprint(n_rack)\nfilename = 'results/{}/{}_{}.pickle'.format(t_n,n_rack,t_n)\nwith open(filename, 'wb') as f:\n    pickle.dump(error_df, f)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "pred_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "pred_list = [item for sublist in pred_list for item in sublist]\npred_list = [float(item) for item in pred_list]\nlen(y_true),len(pred_list)\nerror_df = pd.DataFrame({'prob': pred_list,\n                        'true_class': y_true})\nprint(n_rack)\nfilename = 'results/{}/{}_{}.pickle'.format(t_n,n_rack,t_n)\nwith open(filename, 'wb') as f:\n    pickle.dump(error_df, f)\nfilepath = 'results/model/{}/{}_{}.pth'.format(t_n,n_rack,t_n)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "pred_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "pred_list = [float(item) for item in pred_list]\nlen(y_true),len(pred_list)\nerror_df = pd.DataFrame({'prob': pred_list,\n                        'true_class': y_true})\nprint(n_rack)\nfilename = 'results/{}/{}_{}.pickle'.format(t_n,n_rack,t_n)\nwith open(filename, 'wb') as f:\n    pickle.dump(error_df, f)\nfilepath = 'results/model/{}/{}_{}.pth'.format(t_n,n_rack,t_n)\n#save model",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "error_df",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "error_df = pd.DataFrame({'prob': pred_list,\n                        'true_class': y_true})\nprint(n_rack)\nfilename = 'results/{}/{}_{}.pickle'.format(t_n,n_rack,t_n)\nwith open(filename, 'wb') as f:\n    pickle.dump(error_df, f)\nfilepath = 'results/model/{}/{}_{}.pth'.format(t_n,n_rack,t_n)\n#save model\ntorch.save(model.state_dict(), filepath)\n#load model",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "filename",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "filename = 'results/{}/{}_{}.pickle'.format(t_n,n_rack,t_n)\nwith open(filename, 'wb') as f:\n    pickle.dump(error_df, f)\nfilepath = 'results/model/{}/{}_{}.pth'.format(t_n,n_rack,t_n)\n#save model\ntorch.save(model.state_dict(), filepath)\n#load model\n#model = anomaly_anticipation(*args, **kwargs)\n#model.load_state_dict(torch.load(PATH))\n#model.eval()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "filepath",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "filepath = 'results/model/{}/{}_{}.pth'.format(t_n,n_rack,t_n)\n#save model\ntorch.save(model.state_dict(), filepath)\n#load model\n#model = anomaly_anticipation(*args, **kwargs)\n#model.load_state_dict(torch.load(PATH))\n#model.eval()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "#model",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "peekOfCode": "#model = anomaly_anticipation(*args, **kwargs)\n#model.load_state_dict(torch.load(PATH))\n#model.eval()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.GNN",
        "documentation": {}
    },
    {
        "label": "read_files",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "peekOfCode": "def read_files(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data['value'].to_frame()\n    node_data = node_data.dropna()\n    return node_data\ndef anticipation_transition_stats(df,z_to_z,z_to_o,o_to_o,o_to_z):\n    current = df['new_label'][0]\n    for i in range(1,df.shape[0]):\n        if(current == 0):\n            if(df['new_label'][i]==0):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "documentation": {}
    },
    {
        "label": "anticipation_transition_stats",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "peekOfCode": "def anticipation_transition_stats(df,z_to_z,z_to_o,o_to_o,o_to_z):\n    current = df['new_label'][0]\n    for i in range(1,df.shape[0]):\n        if(current == 0):\n            if(df['new_label'][i]==0):\n                z_to_z = z_to_z + 1\n            else:\n                z_to_o = z_to_o + 1\n                current = 1\n        else:",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "peekOfCode": "def new_label_creation(df,t_n):\n    value = df['value'].to_numpy()\n    new_label = []\n    for i in range(len(value)):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=len(value)):\n                break\n            else: \n                if(value[j]==1):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "documentation": {}
    },
    {
        "label": "racks",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "peekOfCode": "racks = [0,10,12,14,16,18,2,21,23,25,27,29,30,32,34,36,38,40,42,44,46,48,6,8,\n        1,11,13,15,17,19,20,22,24,26,28,3,31,33,35,37,39,4,41,43,45,47,5,7,9]\nfw = [4,6,12,24,32,64,96,192,288]\ndef read_files(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data['value'].to_frame()\n    node_data = node_data.dropna()\n    return node_data\ndef anticipation_transition_stats(df,z_to_z,z_to_o,o_to_o,o_to_z):\n    current = df['new_label'][0]",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "documentation": {}
    },
    {
        "label": "fw",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "peekOfCode": "fw = [4,6,12,24,32,64,96,192,288]\ndef read_files(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data['value'].to_frame()\n    node_data = node_data.dropna()\n    return node_data\ndef anticipation_transition_stats(df,z_to_z,z_to_o,o_to_o,o_to_z):\n    current = df['new_label'][0]\n    for i in range(1,df.shape[0]):\n        if(current == 0):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "documentation": {}
    },
    {
        "label": "roc_avg",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "peekOfCode": "roc_avg = [0,0,0,0,0,0,0,0,0]\nfor rack in racks:\n    print(rack)\n    dir_path = 'data/{}/'.format(rack)\n    files = []\n    # loop over the contents of the directory\n    for filename in os.listdir(dir_path):\n        # construct the full path of the file\n        file_path = os.path.join(dir_path, filename)\n        # check if the file is a regular file (not a directory)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.MC",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "def read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "feature_and_new_label_extract",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "def feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()\n    test_feat = torch.tensor(test_feat, dtype=torch.float)\n    train_label = train_df['new_label']\n    train_label = train_label.to_numpy()\n    train_label = torch.tensor(train_label, dtype=torch.float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "def create_dataset(train_x,test_x,train_y,test_y):\n    train_data = []\n    for i in range(train_x.shape[0]):\n        train_data.append([train_x[i],train_y[i]])\n    test_data = []\n    for i in range(test_x.shape[0]):\n        test_data.append([test_x[i],test_y[i]])\n    return train_data,test_data\ndef new_label_creation(df):\n    new_label = []",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "def new_label_creation(df):\n    new_label = []\n    for i in range(df.shape[0]):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=df.shape[0]):\n                break\n            else: \n                if(df['value'][j]==1):\n                    anomaly_ahead = True",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "inpts = sys.argv\nrack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "rack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "t_n",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "t_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "ln",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "ln = len(str(rack))\nanticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "anticipation",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "anticipation = True\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "n_rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "n_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "dir_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "dir_path = 'data/{}/'.format(rack)\nfiles = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "peekOfCode": "files = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)\nfor i in range(len(files)):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.RF",
        "documentation": {}
    },
    {
        "label": "baseline_1",
        "kind": 6,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "class baseline_1(torch.nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        #encoder\n        self.fc1 = torch.nn.Linear(in_channels, 300)\n        self.fc2 = torch.nn.Linear(300, 100)\n        self.fc3 = torch.nn.Linear(100, 16)\n        #output\n        self.fc4 = torch.nn.Linear(16,1)\n    def forward(self, x):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "read_file",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "def read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "feature_and_new_label_extract",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "def feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])\n    train_feat = train_feat.to_numpy()\n    train_feat = torch.tensor(train_feat, dtype=torch.float)\n    test_feat = test_df.drop(columns=['new_label'])\n    test_feat = test_feat.to_numpy()\n    test_feat = torch.tensor(test_feat, dtype=torch.float)\n    train_label = train_df[['new_label']]\n    train_label = train_label.to_numpy()\n    train_label = torch.tensor(train_label, dtype=torch.float)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "def create_dataset(train_x,test_x,train_y,test_y):\n    train_data = []\n    for i in range(train_x.shape[0]):\n        train_data.append([train_x[i],train_y[i]])\n    test_data = []\n    for i in range(test_x.shape[0]):\n        test_data.append([test_x[i],test_y[i]])\n    return train_data,test_data\nclass baseline_1(torch.nn.Module):\n    def __init__(self, in_channels):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "training",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "def training():\n    model.train()\n    for x,y in loader:\n        x = x.to(device)\n        y = y.to(device)\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n        optimizer.step()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "new_label_creation",
        "kind": 2,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "def new_label_creation(df):\n    new_label = []\n    for i in range(df.shape[0]):\n        anomaly_ahead = False\n        for j in range(i+1,i+1+t_n):\n            if(j>=df.shape[0]):\n                break\n            else: \n                if(df['value'][j]==1):\n                    anomaly_ahead = True",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "inpts",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "inpts = sys.argv\nrack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "rack = int(inpts[1])\nt_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "t_n",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "t_n = int(inpts[2])\nln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "ln",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "ln = len(str(rack))\nanticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "anticipation",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "anticipation = True\n#setting up cuda\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "n_rack",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "n_rack = rack\nprint(rack,t_n)\n#helper functions\n#---------------------------------------------------------------------------------------------------------------\ndef read_file(node_dir):\n    node_data = pd.read_parquet(node_dir)\n    node_data = node_data.dropna()\n    return node_data\ndef feature_and_new_label_extract(train_df,test_df):\n    train_feat = train_df.drop(columns=['new_label'])",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "dir_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "dir_path = 'data/{}/'.format(rack)\nfiles = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "files",
        "kind": 5,
        "importPath": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "description": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "peekOfCode": "files = []\n# loop over the contents of the directory\nfor filename in os.listdir(dir_path):\n    # construct the full path of the file\n    file_path = os.path.join(dir_path, filename)\n    # check if the file is a regular file (not a directory)\n    if os.path.isfile(file_path):\n        files.append(file_path)\nprint(files)\n#checking GPU",
        "detail": "examples.GRAAFE.Offline.Full_pipeline.Training_and_validation_of_ML_models.dense",
        "documentation": {}
    },
    {
        "label": "ExamonQL",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.examon",
        "description": "examples.GRAAFE.Online.examon.examon",
        "peekOfCode": "class ExamonQL(object):\n    \"\"\"Examon query language\n    Provide an high level interface to data queries\n    \"\"\"\n    def __init__(self, examon):\n        self.ex = examon\n        self.metric_list = None\n        self.tag_list = None\n        self.res_df_list = []\n        self.qb = QueryBuilder()",
        "detail": "examples.GRAAFE.Online.examon.examon",
        "documentation": {}
    },
    {
        "label": "Examon",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.examon",
        "description": "examples.GRAAFE.Online.examon.examon",
        "peekOfCode": "class Examon(KairosDb):\n    \"\"\"Examon time-series interface\"\"\"\n    def __init__(self, host, port='8083', user=None, password=None, verbose=True, comp='gzip', proxy=False):\n        \"\"\"Create an Examon object\"\"\"\n        self.json_data = {}\n        self.df_ts = pd.DataFrame()\n        self.df_table = pd.DataFrame()\n        self.dict_table = []\n        self.verbose = verbose\n        self.time_zone = None",
        "detail": "examples.GRAAFE.Online.examon.examon",
        "documentation": {}
    },
    {
        "label": "THREADPOOL_WORKERS",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.examon",
        "description": "examples.GRAAFE.Online.examon.examon",
        "peekOfCode": "THREADPOOL_WORKERS = 16\nclass ExamonQL(object):\n    \"\"\"Examon query language\n    Provide an high level interface to data queries\n    \"\"\"\n    def __init__(self, examon):\n        self.ex = examon\n        self.metric_list = None\n        self.tag_list = None\n        self.res_df_list = []",
        "detail": "examples.GRAAFE.Online.examon.examon",
        "documentation": {}
    },
    {
        "label": "Client",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.examon",
        "description": "examples.GRAAFE.Online.examon.examon",
        "peekOfCode": "Client = Examon",
        "detail": "examples.GRAAFE.Online.examon.examon",
        "documentation": {}
    },
    {
        "label": "ExBase",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.executors",
        "description": "examples.GRAAFE.Online.examon.executors",
        "peekOfCode": "class ExBase(object):\n    def __init__(self, ex):\n        self.ex = ex\n        self.q_slices = []\n    def query(self, tstart, tstop, metric_names, tags=None, groupby=None, aggrby=None, limit=None, time_zone='Europe/Rome', batch_size=30*60*1000):\n        query = QueryBuilder()\n        query.setStart(tstart)\n        query.setEnd(tstop)\n        query.addMetric(metric_names)\n        if tags is not None: # put all metric tags by default",
        "detail": "examples.GRAAFE.Online.examon.executors",
        "documentation": {}
    },
    {
        "label": "ExSpark",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.executors",
        "description": "examples.GRAAFE.Online.examon.executors",
        "peekOfCode": "class ExSpark(ExBase):\n    def __init__(self, ex):\n        from pyspark.sql import Row\n        self.Row = Row\n        super(ExSpark, self).__init__(ex)\n    def spark(self, spark_context):\n        global sc\n        sc = spark_context\n        return self\n    def to_rdd(self, npartitions=None, repartition=None):",
        "detail": "examples.GRAAFE.Online.examon.executors",
        "documentation": {}
    },
    {
        "label": "ExDask",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.executors",
        "description": "examples.GRAAFE.Online.examon.executors",
        "peekOfCode": "class ExDask(ExBase):\n    def __init__(self, ex):\n        import dask.bag as db\n        self.db = db\n        #self.client = None\n        super(ExDask, self).__init__(ex)\n    def dask(self, dask_client=None, **client_kwargs):\n        global client\n        if client is None:\n            if dask_client is None:",
        "detail": "examples.GRAAFE.Online.examon.executors",
        "documentation": {}
    },
    {
        "label": "sc",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.executors",
        "description": "examples.GRAAFE.Online.examon.executors",
        "peekOfCode": "sc = None\n# dask cluster\nclient = None\nclass ExBase(object):\n    def __init__(self, ex):\n        self.ex = ex\n        self.q_slices = []\n    def query(self, tstart, tstop, metric_names, tags=None, groupby=None, aggrby=None, limit=None, time_zone='Europe/Rome', batch_size=30*60*1000):\n        query = QueryBuilder()\n        query.setStart(tstart)",
        "detail": "examples.GRAAFE.Online.examon.executors",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.executors",
        "description": "examples.GRAAFE.Online.examon.executors",
        "peekOfCode": "client = None\nclass ExBase(object):\n    def __init__(self, ex):\n        self.ex = ex\n        self.q_slices = []\n    def query(self, tstart, tstop, metric_names, tags=None, groupby=None, aggrby=None, limit=None, time_zone='Europe/Rome', batch_size=30*60*1000):\n        query = QueryBuilder()\n        query.setStart(tstart)\n        query.setEnd(tstop)\n        query.addMetric(metric_names)",
        "detail": "examples.GRAAFE.Online.examon.executors",
        "documentation": {}
    },
    {
        "label": "JobsClient",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.jobsclient",
        "description": "examples.GRAAFE.Online.examon.jobsclient",
        "peekOfCode": "class JobsClient(KairosDb):\n    \"\"\"Batch scheduler data client\n    Temporary interface to jobs data.\n    Enable the examon client to fetch data from the job tables\n    currently stored in C*.\n    \"\"\"\n    def __init__(self, host, port='5000', user=None, password=None, verbose=False, comp='gzip', proxy=False):\n        self.JOB_TABLES = {'job_info_galileo','job_info_marconi'}  # TODO: make this dynamic\n        self.qs = QuerySlicer()\n        self.q_slices = []",
        "detail": "examples.GRAAFE.Online.examon.jobsclient",
        "documentation": {}
    },
    {
        "label": "KairosDb",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.kairosdb",
        "description": "examples.GRAAFE.Online.examon.kairosdb",
        "peekOfCode": "class KairosDb(object):\n    \"\"\"Kairosdb REST client\n    ...\n    Parameters\n    ----------\n    host : str\n        KairosDB server IP address\n    port : str\n        KairosDB server port. Default is 8083\n    user : str",
        "detail": "examples.GRAAFE.Online.examon.kairosdb",
        "documentation": {}
    },
    {
        "label": "filtkey",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.examon.kairosdb",
        "description": "examples.GRAAFE.Online.examon.kairosdb",
        "peekOfCode": "def filtkey(self, *args, **kwargs):\n    \"\"\"Make mutable objects hashable.\n    Used for complex dict args for cachetools.\n    \"\"\"\n    return pickle.dumps(args, 1) + pickle.dumps(kwargs, 1)\nclass KairosDb(object):\n    \"\"\"Kairosdb REST client\n    ...\n    Parameters\n    ----------",
        "detail": "examples.GRAAFE.Online.examon.kairosdb",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.kairosdb",
        "description": "examples.GRAAFE.Online.examon.kairosdb",
        "peekOfCode": "DEBUG = False\nd_cache = FanoutCache(\"examon-cache\", shards=16, timeout=1)\ndef filtkey(self, *args, **kwargs):\n    \"\"\"Make mutable objects hashable.\n    Used for complex dict args for cachetools.\n    \"\"\"\n    return pickle.dumps(args, 1) + pickle.dumps(kwargs, 1)\nclass KairosDb(object):\n    \"\"\"Kairosdb REST client\n    ...",
        "detail": "examples.GRAAFE.Online.examon.kairosdb",
        "documentation": {}
    },
    {
        "label": "d_cache",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.kairosdb",
        "description": "examples.GRAAFE.Online.examon.kairosdb",
        "peekOfCode": "d_cache = FanoutCache(\"examon-cache\", shards=16, timeout=1)\ndef filtkey(self, *args, **kwargs):\n    \"\"\"Make mutable objects hashable.\n    Used for complex dict args for cachetools.\n    \"\"\"\n    return pickle.dumps(args, 1) + pickle.dumps(kwargs, 1)\nclass KairosDb(object):\n    \"\"\"Kairosdb REST client\n    ...\n    Parameters",
        "detail": "examples.GRAAFE.Online.examon.kairosdb",
        "documentation": {}
    },
    {
        "label": "QueryBuilder",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.querybuilder",
        "description": "examples.GRAAFE.Online.examon.querybuilder",
        "peekOfCode": "class QueryBuilder(object):\n    \"\"\"\n        Kairosdb query builder\n    \"\"\"\n    def __init__(self):\n        self.query = Query(tstart=None,\n                           tstop = None,\n                           metrics = None,\n                           tags = None,\n                           groupby = None,",
        "detail": "examples.GRAAFE.Online.examon.querybuilder",
        "documentation": {}
    },
    {
        "label": "Query",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.examon.querybuilder",
        "description": "examples.GRAAFE.Online.examon.querybuilder",
        "peekOfCode": "Query = namedtuple('Query','tstart tstop metrics tags groupby aggrby limit time_zone')\nclass QueryBuilder(object):\n    \"\"\"\n        Kairosdb query builder\n    \"\"\"\n    def __init__(self):\n        self.query = Query(tstart=None,\n                           tstop = None,\n                           metrics = None,\n                           tags = None,",
        "detail": "examples.GRAAFE.Online.examon.querybuilder",
        "documentation": {}
    },
    {
        "label": "QuerySlicer",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.examon.queryslicer",
        "description": "examples.GRAAFE.Online.examon.queryslicer",
        "peekOfCode": "class QuerySlicer(object):\n    \"\"\"\n        Single Query Batching\n    \"\"\"\n    def __init__(self):\n        self.mills = {'seconds': 1000,\n                           'minutes': 60*1000,\n                           'hours': 60*60*1000,\n                           'days': 24*60*60*1000,\n                           'weeks': 7*24*60*60*1000,",
        "detail": "examples.GRAAFE.Online.examon.queryslicer",
        "documentation": {}
    },
    {
        "label": "examon_client",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.data_extraction",
        "description": "examples.GRAAFE.Online.data_extraction",
        "peekOfCode": "def examon_client(KAIROSDB_SERVER, KAIROSDB_PORT, USER, PWD):\n    ex = Examon(KAIROSDB_SERVER, port=KAIROSDB_PORT, user=USER, password=PWD, verbose=False, proxy=True)\n    sq = ExamonQL(ex)\n    return sq\nasync def dxt(sq, diff, rack_name, metric): \n    if rack_name == 'all':\n        # print('All Racks of Marconi100')\n        df = sq.SELECT('node')\\\n            .FROM(metric)\\\n            .WHERE(cluster='marconi100', plugin='ipmi_pub')\\",
        "detail": "examples.GRAAFE.Online.data_extraction",
        "documentation": {}
    },
    {
        "label": "run_dxt",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.data_extraction",
        "description": "examples.GRAAFE.Online.data_extraction",
        "peekOfCode": "def run_dxt(sq, diff, rack_name, metrics=metrics): \n    result = asyncio.run(run_queries(sq, diff, rack_name, metrics)) \n    return result\ndef append_cutoff_df_raw(df_raw_old, df_raw): \n    df_raw = pd.concat([df_raw, df_raw_old])\n    df_raw.reset_index(inplace=True)\n    df_raw = df_raw.drop_duplicates()\n    if 'timestamp' in df_raw.columns:\n        df_raw.set_index('timestamp', inplace=True)\n    max_index = df_raw.index.max()",
        "detail": "examples.GRAAFE.Online.data_extraction",
        "documentation": {}
    },
    {
        "label": "append_cutoff_df_raw",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.data_extraction",
        "description": "examples.GRAAFE.Online.data_extraction",
        "peekOfCode": "def append_cutoff_df_raw(df_raw_old, df_raw): \n    df_raw = pd.concat([df_raw, df_raw_old])\n    df_raw.reset_index(inplace=True)\n    df_raw = df_raw.drop_duplicates()\n    if 'timestamp' in df_raw.columns:\n        df_raw.set_index('timestamp', inplace=True)\n    max_index = df_raw.index.max()\n    cutoff_index = max_index - datetime.timedelta(seconds=15*60)\n    # filter the dataframe to keep rows after the cutoff index\n    df_raw = df_raw.loc[df_raw.index > cutoff_index]",
        "detail": "examples.GRAAFE.Online.data_extraction",
        "documentation": {}
    },
    {
        "label": "DIFF_minutes",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.data_extraction",
        "description": "examples.GRAAFE.Online.data_extraction",
        "peekOfCode": "def DIFF_minutes(df_raw):\n    try:\n        LAST_INDEX = df_raw.index.max()\n        NOW = datetime.datetime.now(pytz.timezone('Europe/Rome')) \n        DIFF = NOW - LAST_INDEX\n        DIFF =  int((1 + DIFF.total_seconds()))\n        DIFF = min([DIFF, 15*60])\n        print(f'Data of Last {DIFF} Seconds Are Donwloading! - Now : {NOW} - Last Index of Cached Data : {LAST_INDEX}')\n        return DIFF\n    except Exception as e:",
        "detail": "examples.GRAAFE.Online.data_extraction",
        "documentation": {}
    },
    {
        "label": "metrics",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.data_extraction",
        "description": "examples.GRAAFE.Online.data_extraction",
        "peekOfCode": "metrics = pd.read_csv('metrics').metrics.values.tolist()\ndef run_dxt(sq, diff, rack_name, metrics=metrics): \n    result = asyncio.run(run_queries(sq, diff, rack_name, metrics)) \n    return result\ndef append_cutoff_df_raw(df_raw_old, df_raw): \n    df_raw = pd.concat([df_raw, df_raw_old])\n    df_raw.reset_index(inplace=True)\n    df_raw = df_raw.drop_duplicates()\n    if 'timestamp' in df_raw.columns:\n        df_raw.set_index('timestamp', inplace=True)",
        "detail": "examples.GRAAFE.Online.data_extraction",
        "documentation": {}
    },
    {
        "label": "anomaly_anticipation",
        "kind": 6,
        "importPath": "examples.GRAAFE.Online.inference",
        "description": "examples.GRAAFE.Online.inference",
        "peekOfCode": "class anomaly_anticipation(torch.nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        #encoder\n        self.conv1 = GCNConv(in_channels, 300)\n        self.conv2 = GCNConv(300, 100)\n        self.conv3 = GCNConv(100, out_channels)\n        #dense layer\n        self.fc1 = torch.nn.Linear(out_channels,16)\n        self.fc2 = torch.nn.Linear(16,1)",
        "detail": "examples.GRAAFE.Online.inference",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.inference",
        "description": "examples.GRAAFE.Online.inference",
        "peekOfCode": "def inference(model,graph):\n    out = model(graph.x,graph.edge_index)\n    prediction = torch.sigmoid(out)\n    return prediction",
        "detail": "examples.GRAAFE.Online.inference",
        "documentation": {}
    },
    {
        "label": "check_dir",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "def check_dir(path):\n    if not os.path.isdir(path):\n        os.makedirs(path)\n        print(path+\" ==> CREATED.\")\nloggin_path = './log/'\ncheck_dir(loggin_path)\nlog_file_name = 'log' + '-' + datetime.datetime.strftime(datetime.datetime.now(pytz.timezone('Europe/Rome')), '%Y-%m-%d').replace(':','-').replace(' ','-')+'.log'\nformatter = '%(levelname)s:%(lineno)d:%(process)d:%(processName)s:%(thread)d:%(threadName)s:%(asctime)s:%(message)s'\nlogging.basicConfig(filename=os.path.join(loggin_path,log_file_name),\n                    level=logging.INFO,",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "def start_time(title, logging):    \n    time_format = \"%Y-%m-%d-%H-%M-%S.%f\"\n    start_time = time.time()\n    formatted_start_time = datetime.datetime.fromtimestamp(start_time).astimezone(rome_timezone).strftime(time_format)\n    print(f\"{title} start time: {formatted_start_time}\")\n    logging.info(f\"{title} Start time: {formatted_start_time}\")\n    return start_time\ndef end_time(title, logging, start_time):  \n    time_format = \"%Y-%m-%d-%H-%M-%S.%f\"\n    end_time = time.time()",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "end_time",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "def end_time(title, logging, start_time):  \n    time_format = \"%Y-%m-%d-%H-%M-%S.%f\"\n    end_time = time.time()\n    formatted_end_time = datetime.datetime.fromtimestamp(end_time).astimezone(rome_timezone).strftime(time_format)\n    print(f\"{title} End time: {formatted_end_time}\")\n    logging.info(f\"{title} End time: {formatted_end_time}\")\n    print(f\"{title} Time taken: {end_time - start_time} seconds\")\n    logging.info(f\"{title} Time taken: {end_time - start_time} seconds\")\n    return end_time - start_time",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "rome_timezone",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "rome_timezone = pytz.timezone('Europe/Rome')\ndef check_dir(path):\n    if not os.path.isdir(path):\n        os.makedirs(path)\n        print(path+\" ==> CREATED.\")\nloggin_path = './log/'\ncheck_dir(loggin_path)\nlog_file_name = 'log' + '-' + datetime.datetime.strftime(datetime.datetime.now(pytz.timezone('Europe/Rome')), '%Y-%m-%d').replace(':','-').replace(' ','-')+'.log'\nformatter = '%(levelname)s:%(lineno)d:%(process)d:%(processName)s:%(thread)d:%(threadName)s:%(asctime)s:%(message)s'\nlogging.basicConfig(filename=os.path.join(loggin_path,log_file_name),",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "loggin_path",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "loggin_path = './log/'\ncheck_dir(loggin_path)\nlog_file_name = 'log' + '-' + datetime.datetime.strftime(datetime.datetime.now(pytz.timezone('Europe/Rome')), '%Y-%m-%d').replace(':','-').replace(' ','-')+'.log'\nformatter = '%(levelname)s:%(lineno)d:%(process)d:%(processName)s:%(thread)d:%(threadName)s:%(asctime)s:%(message)s'\nlogging.basicConfig(filename=os.path.join(loggin_path,log_file_name),\n                    level=logging.INFO,\n                    format=formatter)\ndef start_time(title, logging):    \n    time_format = \"%Y-%m-%d-%H-%M-%S.%f\"\n    start_time = time.time()",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "log_file_name",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "log_file_name = 'log' + '-' + datetime.datetime.strftime(datetime.datetime.now(pytz.timezone('Europe/Rome')), '%Y-%m-%d').replace(':','-').replace(' ','-')+'.log'\nformatter = '%(levelname)s:%(lineno)d:%(process)d:%(processName)s:%(thread)d:%(threadName)s:%(asctime)s:%(message)s'\nlogging.basicConfig(filename=os.path.join(loggin_path,log_file_name),\n                    level=logging.INFO,\n                    format=formatter)\ndef start_time(title, logging):    \n    time_format = \"%Y-%m-%d-%H-%M-%S.%f\"\n    start_time = time.time()\n    formatted_start_time = datetime.datetime.fromtimestamp(start_time).astimezone(rome_timezone).strftime(time_format)\n    print(f\"{title} start time: {formatted_start_time}\")",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "formatter",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.logging_module",
        "description": "examples.GRAAFE.Online.logging_module",
        "peekOfCode": "formatter = '%(levelname)s:%(lineno)d:%(process)d:%(processName)s:%(thread)d:%(threadName)s:%(asctime)s:%(message)s'\nlogging.basicConfig(filename=os.path.join(loggin_path,log_file_name),\n                    level=logging.INFO,\n                    format=formatter)\ndef start_time(title, logging):    \n    time_format = \"%Y-%m-%d-%H-%M-%S.%f\"\n    start_time = time.time()\n    formatted_start_time = datetime.datetime.fromtimestamp(start_time).astimezone(rome_timezone).strftime(time_format)\n    print(f\"{title} start time: {formatted_start_time}\")\n    logging.info(f\"{title} Start time: {formatted_start_time}\")",
        "detail": "examples.GRAAFE.Online.logging_module",
        "documentation": {}
    },
    {
        "label": "map_rack_name",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.main",
        "description": "examples.GRAAFE.Online.main",
        "peekOfCode": "map_rack_name = {'r205':0,'r206':1,'r207':2,'r208':3,'r209':4,'r210':5,'r211':6,'r212':7,'r213':8,'r214':9,\n                 'r215':10,'r216':11,'r217':12,'r218':13,'r219':14,'r220':15,'r221':16,'r222':17,'r223':18,'r224':19,\n                 'r225':20,'r226':21,'r227':22,'r228':23,'r229':24,'r231':25,'r232':26,'r233':27,'r234':28,'r236':29,\n                 'r237':30,'r238':31,'r239':32,'r240':33,'r241':34,'r242':35,'r243':36,'r244':37,'r245':38,'r246':39,\n                 'r247':40,'r248':41,'r249':42,'r250':43,'r251':44,'r253':45,'r254':46,'r255':47,'r256':48}\nrack_name_list = map_rack_name.keys()\nif __name__ == '__main__':\n    print(\"-------------------------  __main__  -------------------------\")\n    parser = argparse.ArgumentParser(description='My script description')\n    parser.add_argument('-ir', '--inference_rate', type=int, help='This shows the inference rate in seconds.',default=0)",
        "detail": "examples.GRAAFE.Online.main",
        "documentation": {}
    },
    {
        "label": "rack_name_list",
        "kind": 5,
        "importPath": "examples.GRAAFE.Online.main",
        "description": "examples.GRAAFE.Online.main",
        "peekOfCode": "rack_name_list = map_rack_name.keys()\nif __name__ == '__main__':\n    print(\"-------------------------  __main__  -------------------------\")\n    parser = argparse.ArgumentParser(description='My script description')\n    parser.add_argument('-ir', '--inference_rate', type=int, help='This shows the inference rate in seconds.',default=0)\n    parser.add_argument('-r', '--rack_name', type=str, help='Rack Name, all mesans all racks of the M100 one by one in serial approach. ',default='r256')\n    parser.add_argument('-ph', '--prediction_horizon', type=int, help='Prediction Horizon. ',default=24)\n    # ExaMon\n    parser.add_argument('-es', '--examon_server', type=str, help='KAIROSDB_SERVER = \"examon.cineca.it\"', default=\"examon.cineca.it\")\n    parser.add_argument('-ep', '--examon_port', type=str, help='KAIROSDB_PORT = \"3000\"',default=\"3000\")",
        "detail": "examples.GRAAFE.Online.main",
        "documentation": {}
    },
    {
        "label": "graph_rack",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.preprocessing",
        "description": "examples.GRAAFE.Online.preprocessing",
        "peekOfCode": "def graph_rack(df_raw, rack_name):\n    df_agg = agg_df_avg_min_max_std(df_raw)\n    df_rack = rack_df(df_agg, rack_name=rack_name)     \n    dg_rack = convert_to_graph_data(df_rack)\n    return dg_rack\ndef agg_df_avg_min_max_std(df):\n    df_agg = pd.concat(\n        [df.groupby(['name', 'node']).mean().pivot_table(index='node', columns='name').add_suffix('_avg'),\n         df.groupby(['name', 'node']).std().pivot_table(index='node', columns='name').add_suffix('_std'),\n         df.groupby(['name', 'node']).min().pivot_table(index='node', columns='name').add_suffix('_min'),",
        "detail": "examples.GRAAFE.Online.preprocessing",
        "documentation": {}
    },
    {
        "label": "agg_df_avg_min_max_std",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.preprocessing",
        "description": "examples.GRAAFE.Online.preprocessing",
        "peekOfCode": "def agg_df_avg_min_max_std(df):\n    df_agg = pd.concat(\n        [df.groupby(['name', 'node']).mean().pivot_table(index='node', columns='name').add_suffix('_avg'),\n         df.groupby(['name', 'node']).std().pivot_table(index='node', columns='name').add_suffix('_std'),\n         df.groupby(['name', 'node']).min().pivot_table(index='node', columns='name').add_suffix('_min'),\n         df.groupby(['name', 'node']).max().pivot_table(index='node', columns='name').add_suffix('_max')],\n        axis=1, ignore_index=False)\n    df_agg.columns = df_agg.columns.droplevel(0)\n    df_agg['value'] = 0\n    return df_agg",
        "detail": "examples.GRAAFE.Online.preprocessing",
        "documentation": {}
    },
    {
        "label": "rack_df",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.preprocessing",
        "description": "examples.GRAAFE.Online.preprocessing",
        "peekOfCode": "def rack_df(df, rack_name):\n    df = df.loc[df.index.str.contains(rack_name)]\n    df = df.sort_index(axis=0)\n    df = df.sort_index(axis=1)\n    return df\ndef convert_to_graph_data(df):\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)\n    df = df.astype(float)\n    df['value'] = df['value'].replace(2,1)",
        "detail": "examples.GRAAFE.Online.preprocessing",
        "documentation": {}
    },
    {
        "label": "convert_to_graph_data",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.preprocessing",
        "description": "examples.GRAAFE.Online.preprocessing",
        "peekOfCode": "def convert_to_graph_data(df):\n    df.reset_index(drop=True, inplace = True)\n    df = df.fillna(0)\n    df = df.astype(float)\n    df['value'] = df['value'].replace(2,1)\n    df['value'] = df['value'].replace(3,1)\n    n_nodes = df.shape[0]\n    edges = []\n    k = 0\n    for i in range(n_nodes):",
        "detail": "examples.GRAAFE.Online.preprocessing",
        "documentation": {}
    },
    {
        "label": "sleep_time",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.preprocessing",
        "description": "examples.GRAAFE.Online.preprocessing",
        "peekOfCode": "def sleep_time(rate, loop_taken_time):\n    sl_t = rate - loop_taken_time\n    if sl_t <= 0:\n        sl_t = 0\n    return sl_t",
        "detail": "examples.GRAAFE.Online.preprocessing",
        "documentation": {}
    },
    {
        "label": "gnn_topic_creator",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.publishing_results",
        "description": "examples.GRAAFE.Online.publishing_results",
        "peekOfCode": "def gnn_topic_creator(node_name):\n    topic = f\"org/cineca/cluster/marconi100/node/{node_name}/room/f/plugin/examon-ai_pub/chnl/data/config/debug/gnn\"\n    return topic \ndef gnn_mqtt_client_instance(broker_address,broker_port):\n    print('----------- Create an MQTT Client Instance -----------')\n    # create an MQTT client instance\n    client = mqtt.Client()\n    # set the connection parameters for the broker\n    client.connect(broker_address, broker_port)\n    return client",
        "detail": "examples.GRAAFE.Online.publishing_results",
        "documentation": {}
    },
    {
        "label": "gnn_mqtt_client_instance",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.publishing_results",
        "description": "examples.GRAAFE.Online.publishing_results",
        "peekOfCode": "def gnn_mqtt_client_instance(broker_address,broker_port):\n    print('----------- Create an MQTT Client Instance -----------')\n    # create an MQTT client instance\n    client = mqtt.Client()\n    # set the connection parameters for the broker\n    client.connect(broker_address, broker_port)\n    return client\ndef on_publish(client, userdata, result):\n    # print(\"Data published to MQTT\")\n    pass",
        "detail": "examples.GRAAFE.Online.publishing_results",
        "documentation": {}
    },
    {
        "label": "on_publish",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.publishing_results",
        "description": "examples.GRAAFE.Online.publishing_results",
        "peekOfCode": "def on_publish(client, userdata, result):\n    # print(\"Data published to MQTT\")\n    pass\ndef gnn_pub(topic, val, client): \n    try:\n        (result, mid) = client.publish(topic, '{0};{1}'.format(val, time.time()))\n        if result == mqtt.MQTT_ERR_SUCCESS:\n            print(f\"Data published successfully. message ID:{mid}\")\n        elif result == mqtt.MQTT_ERR_NO_CONN:\n            print(f\"Error: Connection refused or network error. message ID:{mid}\")",
        "detail": "examples.GRAAFE.Online.publishing_results",
        "documentation": {}
    },
    {
        "label": "gnn_pub",
        "kind": 2,
        "importPath": "examples.GRAAFE.Online.publishing_results",
        "description": "examples.GRAAFE.Online.publishing_results",
        "peekOfCode": "def gnn_pub(topic, val, client): \n    try:\n        (result, mid) = client.publish(topic, '{0};{1}'.format(val, time.time()))\n        if result == mqtt.MQTT_ERR_SUCCESS:\n            print(f\"Data published successfully. message ID:{mid}\")\n        elif result == mqtt.MQTT_ERR_NO_CONN:\n            print(f\"Error: Connection refused or network error. message ID:{mid}\")\n        elif result == mqtt.MQTT_ERR_QUEUE_SIZE:\n            print(f\"Error: Publish queue is full. message ID:{mid}\")\n        elif result == mqtt.MQTT_ERR_PAYLOAD_SIZE:",
        "detail": "examples.GRAAFE.Online.publishing_results",
        "documentation": {}
    }
]